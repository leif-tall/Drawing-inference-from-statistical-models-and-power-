##Chunk for standar kjøringer

```{r}

library(tidyverse)
library(exscidata)
library(gt)
```

##Oppsett siumulation

```{r}
set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)


samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

summary(m1)
summary(m2)
```

### ##Oppgave 1: Explain the estimate, SE, *t*-value, and *p*-value from the regression models that we created previously (`m1` and `m2`).\*\*

Vi har over gjennomført en regresjonsanalyse av de to studiene m1 og m2. Dette er tall som er henta fra det samme tall materialet. Det er studier som er gjort av 1000 observasjoner med fire ulike variabler. En har gjort forskjell mellom de ulike med å ha en forskjell i antall personer i de to studiene. M1 har n=8 mens m2 har n= 40 no som skaper litt forskjellige tall, selv om veldig mye er likt.

```{r}

mean(samp1$y)
```

Når vi har gjennomført regresjonsmodellen har vi gjennomført de følgende statistiske testene på de tallene vi har fått. Dette har i gitt oss et estimat på m1 på 1,290 og m2 på 1.4799, dette gjer oss svare på kva y vill være i når vi starter modellen på 1. ???

SE:

T-value: Vi kan enkelt forklare testen som ein analyse som tar for seg gjennomsnittet mellom to grupper. Ut i frå gjennomsnittet av desse to gruppene, vil t testen kunne sei noko om denne kom frå tilfeldig forandring.

P-value

summary m1: estimate = 0,1301, std error = 1,372, t value = 0,94, pr= 0,378

Summary m2:timate = 1.476, standar error = 0,467, t-value 3.953 pr 0,000315

estimat er gjemmnisitttet i mitt utvalg. Sjekk det tilfeldige utvalget me haddeavmean

### ##Oppgave 2: Discuss what contributes to the different results in the two studies (`m1` and `m2`).\*\*

Selv om vi har trekt forsøkspersonene ut i frå den samme populasjonen. Vi har gjennomført like mange observasjoer av dei fire ulike variablene. Ved å gjennomføre statstiske tester på dei to utvalga får me:

M1: Estimante 0.1301, standarfeil 0,6434, t.-value 0.202

M2: Estimate 1.476, standarfeil 0,467, t value 3.162

Som me ser av dei statisiske som er gjennomført over ved hjelp av summary funsjonen i R. Vi får da fram en forskjell i både estimatet, standar feilen og t-value. Forskjellen frå desse to studiene ligger i forskjellen i N. For samp1 er det bare 8 personer, men i samp 2 er det heile 40 personer. Dette viser oss at vi kan få gangske ulike resultater frå statistiske analyser selv om vi gjennomføre dei samme testene. Også grunnen til at vi ser på en studie at den blir meir reel etter flere personer via har med i studien.

### ##Oppgave 3: Why do we use the shaded area in the lower and upper tail of the *t*-distribution (See Figure\*\* \@ref(fig:t-dist-fig)**).**

For å kunne forklare kvifor vi bruker de skyggelage delene i den øvre og nedre delene av en normalfordelingskurse, så er det hensiktsmessig å forklare kva me bruker denne til. En normalfordelingskurve er en funksjon som beskriver fordelingen av verdier for ein variabel, der ein ikkje har eit fast mønster i fordelingen. Høyden på grafen viser at største delen av fordelingen plasserer seg rundt mitten. Men ein har verdier som er utskudd frå dette og disse legger seg ute på sidene. <https://www.mn.uio.no/ibv/tjenester/kunnskap/plantefys/matematikk/normalfordeling.html>

En normal fordelingskurve tar utgangspunktet i at 95 prosent av populasjonen som via har hentet ut tallmatriale. Vill være innenfor gjennomsnittet +/- to standaravik, og at 99,8 prosent vill være innanfor tre standar avik. Når vi skal se på et tall i forhold til normalfordelingskurven, vill vi da kunne gi tallet en *Z-skår.* Denne beskriver kor mange standar avik ein oppservasjon vi ønsker å undersøke er fra gjennomsnittet. Når vi har flere observasjoner som ligger innanfor det samme område, kan vi beskrive at de ligger innenfor samme *persentil*. Når vi tar utgangspunkt i normalfordelingskurven, så er mitten(medianen) i kurven den 50 persentilie. Ut i fra denne beregner en den 25 og den 75 persentil. Disse er også kjent som *kvartiler(Spiegelhalter, s. 89).* For å kunne skille kvartilene fra andre deler av kurven er disse ofte fargelagt i en annan farge, her finner en verdiene som er ekstreme og ikkje legger sei i den 50 th persentil. <https://tma4245.math.ntnu.no/stokastiske-variabler-og-fordelinger/kvantil/>. Avstanden mellom de to kvartilene er målet på distrubisjonen i data settet.

```{r}
# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}

# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)
```

### ##Oppgave 4: Calculate the standard deviation of the `estimate` variable, and the average of the `se` variable for each of the study sample sizes (8 and 40). Explain why these numbers are very similar. How can you define the Standard Error (SE) in light of these calculations?\*\*

Standar avik av estimatet

```{r}
m <- mean(results)
s <- sd(results)
```

### ##Oppgave 5: Create a histogram (see example code below) of the *p*-values from each study sample-size. How do you interpret these histograms, what do they tell you about the effect of sample size on statistical power?\*\*

### ##Oppgave 6: Calculate the number of studies from each sample size that declare a statistical significant effect (specify a threshold for , your significance level).\*\*

### ##Oppgave 7: Using the `pwr` package, calculate the power of a one-sample t-test, with a effect size of `1.5/3`, your specified significance level and sample sizes 8 and 40. Explain the results in the light of your simulations.\*\*

```{r}
install.packages("pwr")
library(pwr)
```

### ##Oppgave 8: With a significance level of 5%, how many studies would give you a "false positive" result if you did many repeated studies?\*\*
