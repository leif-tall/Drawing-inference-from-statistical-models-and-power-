##Chunk for standar kjøringer

```{r}

library(tidyverse)
library(exscidata)
library(gt)
```

##Oppsett siumulation

```{r}
set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)


samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

summary(m1)
summary(m2)
```

##Oppgave 1: Explain the estimate, SE, *t*-value, and *p*-value from the regression models that we created previously (`m1` and `m2`).\*\*

estimate er gjennomsnittet i dei to utvalgene

```{r}

mean(samp1$y)
```

SE:

T-value: Vi kan enkelt forklare testen som ein analyse som tar for seg gjennomsnittet mellom to grupper. Ut i frå gjennomsnittet av desse to gruppene, vil t testen kunne sei noko om denne kom frå tilfeldig forandring.

P-value

summary m1: estimate = 0,1301, std error = 0,6434, t value = 0,202, pr= 0,846

Summary m2:Stimate = 1.476, standar error = 0,467, t-value 3.162

estimat er gjemmnisitttet i mitt utvalg. Sjekk det tilfeldige utvalget me haddeavmean

##Oppgave 2: Discuss what contributes to the different results in the two studies (`m1` and `m2`).\*\*

Selv om vi har trekt forsøkspersonene ut i frå den samme populasjonen. Vi har gjennomført like mange observasjoer av dei fire ulike variablene. Ved å gjennomføre statstiske tester på dei to utvalga får me:

M1: Estimante 0.1301, standarfeil 0,6434, t.-value 0.202

M2: Estimate 1.476, standarfeil 0,467, t value 3.162

Som me ser av dei statisiske som er gjennomført over ved hjelp av summary funsjonen i R. Vi får da fram en forskjell i både estimatet, standar feilen og t-value. Forskjellen frå desse to studiene ligger i forskjellen i N. For samp1 er det bare 8 personer, men i samp 2 er det heile 40 personer. Dette viser oss at vi kan få gangske ulike resultater frå statistiske analyser selv om vi gjennomføre dei samme testene. Også grunnen til at vi ser på en studie at den blir meir reel etter flere personer via har med i studien.

##Oppgave 3: Why do we use the shaded area in the lower and upper tail of the *t*-distribution (See Figure\*\* \@ref(fig:t-dist-fig)**).**

For å kunne forklare kvifor vi bruker de skyggelage delene i den øvre og den nedre delene av ein t-distribusjonskurve. Så er det først hensiktsmessig å forklare kva vi bruker en t-distribusjonskurve til eller som det også kalles ein normalfordelingskurve. En normalfordelingskurve er en funksjon som beskriver fordelingen av verdier for ein variabel, der ein ikkje har eit fast mønster i fordelingen. Høyden på grafen viser at største delen av fordelingen plasserer seg rundt mitten. Men ein har verdier som er utskudd frå dette og disse legger seg ute på sidene. <https://www.mn.uio.no/ibv/tjenester/kunnskap/plantefys/matematikk/normalfordeling.html>

Det er slik at ein normalfordelingskurve også tar hensyn til at ikkje alle tall følger "normalen og legger seg til rette under mitten. Dermed vill sidene som ofte blir presentert i skraverte farger, stede som prsentere verdiene som er "ekstreme". I forhold til normalverdien, dette blir refert til som kvantiler.

<https://tma4245.math.ntnu.no/stokastiske-variabler-og-fordelinger/kvantil/>

```{r}
# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}

# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)
```

##Oppgave 4: Calculate the standard deviation of the `estimate` variable, and the average of the `se` variable for each of the study sample sizes (8 and 40). Explain why these numbers are very similar. How can you define the Standard Error (SE) in light of these calculations?\*\*

Standar avik av estimatet

```{r}
m <- mean(results)
s <- sd(results)
```

##Oppgave 5: Create a histogram (see example code below) of the *p*-values from each study sample-size. How do you interpret these histograms, what do they tell you about the effect of sample size on statistical power?\*\*

##Oppgave 6: Calculate the number of studies from each sample size that declare a statistical significant effect (specify a threshold for , your significance level).\*\*

##Oppgave 7: Using the `pwr` package, calculate the power of a one-sample t-test, with a effect size of `1.5/3`, your specified significance level and sample sizes 8 and 40. Explain the results in the light of your simulations.\*\*

```{r}
install.packages("pwr")
library(pwr)
```

##Oppgave 8: With a significance level of 5%, how many studies would give you a "false positive" result if you did many repeated studies?\*\*
